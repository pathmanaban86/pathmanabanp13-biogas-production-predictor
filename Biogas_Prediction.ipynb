{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DATA FEATURE ANALYSIS**"
      ],
      "metadata": {
        "id": "sTRPJYZNO-KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Low carbon model/biogas_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "display(df.head())\n",
        "df.info()\n",
        "print(\"\\nMissing values per column:\")\n",
        "display(df.isnull().sum())\n",
        "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
        "df = df.drop_duplicates()\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n",
        "display(df.describe().T)\n",
        "display(df.describe(include=['object']))\n",
        "num_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "range_df = pd.DataFrame({\n",
        "    \"Min\": num_df.min(),\n",
        "    \"Max\": num_df.max(),\n",
        "    \"Range\": num_df.max() - num_df.min()\n",
        "})\n",
        "display(range_df)\n",
        "skewness = num_df.skew()\n",
        "display(skewness)\n",
        "corr_matrix = num_df.corr()\n",
        "display(corr_matrix.head())\n",
        "corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "corr_pairs = corr_pairs[corr_pairs < 1]  # remove self-correlation\n",
        "display(corr_pairs.head(10))\n",
        "Q1 = num_df.quantile(0.25)\n",
        "Q3 = num_df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = ((num_df < lower_bound) | (num_df > upper_bound)).sum()\n",
        "display(outliers)\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    print(\"Unique count:\", df[col].nunique())\n",
        "    print(df[col].value_counts().head())\n",
        "summary = df.describe().T\n",
        "summary_path = \"/content/drive/MyDrive/Low carbon model/dataset_summary.csv\"\n",
        "summary.to_csv(summary_path)\n",
        "print(f\"Summary saved to: {summary_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6VSS302CaRBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPLORATORY DATA ANALYSIS FOR BIOGAS PRODUCTION DATASET**"
      ],
      "metadata": {
        "id": "GHYhiqZVNbi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Low carbon model/biogas_dataset.csv'\n",
        "output_path = '/content/drive/MyDrive/Low carbon model/'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BIOGAS PRODUCTION DATASET - EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Date range: {df['Year'].min()}-{df['Year'].max()}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "print(\"\\nüìä COLUMN INFORMATION:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nüìä FIRST FEW ROWS:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nüìä BASIC STATISTICS:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nüìä MISSING VALUES:\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0] if any(missing > 0) else \"No missing values!\")\n",
        "\n",
        "\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "df['Season'] = df['Month'].apply(lambda x:\n",
        "    'Winter' if x in [12, 1, 2] else\n",
        "    'Spring' if x in [3, 4, 5] else\n",
        "    'Summer' if x in [6, 7, 8] else 'Fall')\n",
        "\n",
        "print(\"\\nüìà Generating distribution plots...\")\n",
        "\n",
        "# Separate variable groups\n",
        "feedstocks = ['Pig Manure (kg)', 'Kitchen Food Waste (kg)', 'Chicken Litter (kg)',\n",
        "              'Cassava (kg)', 'Bagasse Feed (kg)', 'Energy Grass (kg)',\n",
        "              'Banana Shafts (kg)', 'Alcohol Waste (kg)', 'Municipal Residue (kg)',\n",
        "              'Fish Waste (kg)']\n",
        "\n",
        "operational = ['Water (L)', 'Diesel (L)', 'Electricity Use (kWh)',\n",
        "               'C/N Ratio', 'Digester Temp (C)']\n",
        "\n",
        "climate = ['Temperature (C)', 'Humidity (%)', 'Rainfall (mm)']\n",
        "\n",
        "target = ['biogas_production']\n",
        "\n",
        "# Plot distributions - Feedstocks\n",
        "fig, axes = plt.subplots(5, 2, figsize=(15, 18))\n",
        "fig.suptitle('Distribution of Feedstock Inputs', fontsize=16, fontweight='bold')\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(feedstocks):\n",
        "    axes[idx].hist(df[col], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[idx].set_title(col, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Amount (kg)')\n",
        "    axes[idx].set_ylabel('Frequency')\n",
        "    axes[idx].grid(alpha=0.3)\n",
        "\n",
        "    # Add statistics\n",
        "    mean_val = df[col].mean()\n",
        "    median_val = df[col].median()\n",
        "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
        "    axes[idx].legend(fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_01_feedstock_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Plot distributions - Operational & Climate\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "fig.suptitle('Distribution of Operational & Climate Variables', fontsize=16, fontweight='bold')\n",
        "axes = axes.ravel()\n",
        "\n",
        "all_vars = operational + climate + target\n",
        "\n",
        "for idx, col in enumerate(all_vars):\n",
        "    axes[idx].hist(df[col], bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "    axes[idx].set_title(col, fontweight='bold')\n",
        "    axes[idx].set_ylabel('Frequency')\n",
        "    axes[idx].grid(alpha=0.3)\n",
        "\n",
        "    # Add statistics\n",
        "    mean_val = df[col].mean()\n",
        "    median_val = df[col].median()\n",
        "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
        "    axes[idx].legend(fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_02_operational_climate_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "\n",
        "print(\"\\nüìà Analyzing biogas production patterns...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Biogas Production Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Distribution\n",
        "axes[0, 0].hist(df['biogas_production'], bins=60, color='green', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_title('Biogas Production Distribution', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Biogas Production (L)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].axvline(df['biogas_production'].mean(), color='red', linestyle='--',\n",
        "                   linewidth=2, label=f\"Mean: {df['biogas_production'].mean():.2f} L\")\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "axes[0, 1].boxplot(df['biogas_production'], vert=True)\n",
        "axes[0, 1].set_title('Biogas Production Box Plot', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Time series\n",
        "axes[1, 0].plot(df['Date'], df['biogas_production'], alpha=0.6, linewidth=0.5)\n",
        "axes[1, 0].set_title('Biogas Production Over Time', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# QQ plot for normality\n",
        "stats.probplot(df['biogas_production'], dist=\"norm\", plot=axes[1, 1])\n",
        "axes[1, 1].set_title('Q-Q Plot (Normality Check)', fontweight='bold')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_03_biogas_production_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Temporal Trends in Biogas Production', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Yearly trend\n",
        "yearly_avg = df.groupby('Year')['biogas_production'].agg(['mean', 'std', 'count'])\n",
        "axes[0, 0].plot(yearly_avg.index, yearly_avg['mean'], marker='o', linewidth=2, markersize=8)\n",
        "axes[0, 0].fill_between(yearly_avg.index,\n",
        "                        yearly_avg['mean'] - yearly_avg['std'],\n",
        "                        yearly_avg['mean'] + yearly_avg['std'],\n",
        "                        alpha=0.3)\n",
        "axes[0, 0].set_title('Yearly Average Biogas Production', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Year')\n",
        "axes[0, 0].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Monthly trend\n",
        "monthly_avg = df.groupby('Month')['biogas_production'].agg(['mean', 'std'])\n",
        "axes[0, 1].plot(monthly_avg.index, monthly_avg['mean'], marker='o', linewidth=2, markersize=8, color='orange')\n",
        "axes[0, 1].fill_between(monthly_avg.index,\n",
        "                        monthly_avg['mean'] - monthly_avg['std'],\n",
        "                        monthly_avg['mean'] + monthly_avg['std'],\n",
        "                        alpha=0.3, color='orange')\n",
        "axes[0, 1].set_title('Monthly Average Biogas Production', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Month')\n",
        "axes[0, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 1].set_xticks(range(1, 13))\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Seasonal comparison\n",
        "seasonal_data = df.groupby('Season')['biogas_production'].apply(list)\n",
        "axes[1, 0].boxplot([seasonal_data[s] for s in ['Winter', 'Spring', 'Summer', 'Fall']],\n",
        "                   labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
        "axes[1, 0].set_title('Seasonal Biogas Production', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Day of month trend\n",
        "daily_avg = df.groupby('Day')['biogas_production'].mean()\n",
        "axes[1, 1].plot(daily_avg.index, daily_avg.values, marker='o', linewidth=2, markersize=6, color='green')\n",
        "axes[1, 1].set_title('Average Biogas Production by Day of Month', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Day of Month')\n",
        "axes[1, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_04_temporal_trends.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numerical_cols = [col for col in numerical_cols if col not in ['Year', 'Month', 'Day']]\n",
        "\n",
        "correlation_matrix = df[numerical_cols].corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 14))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
        "            annot_kws={'size': 8})\n",
        "plt.title('Correlation Matrix - All Variables', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_05_correlation_full.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Correlation with biogas production specifically\n",
        "biogas_corr = correlation_matrix['biogas_production'].sort_values(ascending=False)\n",
        "print(\"\\nüìä TOP CORRELATIONS WITH BIOGAS PRODUCTION:\")\n",
        "print(biogas_corr)\n",
        "\n",
        "# Plot top correlations\n",
        "fig, ax = plt.subplots(figsize=(10, 12))\n",
        "biogas_corr_sorted = biogas_corr.drop('biogas_production')  # Remove self-correlation\n",
        "colors = ['green' if x > 0 else 'red' for x in biogas_corr_sorted.values]\n",
        "biogas_corr_sorted.plot(kind='barh', color=colors, ax=ax)\n",
        "ax.set_title('Correlation with Biogas Production', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Correlation Coefficient')\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_06_biogas_correlations.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "# Calculate total feedstock per observation\n",
        "df['Total_Feedstock'] = df[feedstocks].sum(axis=1)\n",
        "\n",
        "# Calculate feedstock proportions\n",
        "feedstock_props = df[feedstocks].sum() / df['Total_Feedstock'].sum() * 100\n",
        "\n",
        "# Pie chart\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Feedstock Composition Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Pie chart of total usage\n",
        "colors_pie = plt.cm.Set3(range(len(feedstocks)))\n",
        "axes[0].pie(feedstock_props.values, labels=feedstock_props.index, autopct='%1.1f%%',\n",
        "           startangle=90, colors=colors_pie)\n",
        "axes[0].set_title('Overall Feedstock Composition (%)', fontweight='bold')\n",
        "\n",
        "# Bar chart of average usage\n",
        "feedstock_avg = df[feedstocks].mean().sort_values(ascending=False)\n",
        "axes[1].barh(range(len(feedstock_avg)), feedstock_avg.values, color='steelblue')\n",
        "axes[1].set_yticks(range(len(feedstock_avg)))\n",
        "axes[1].set_yticklabels(feedstock_avg.index)\n",
        "axes[1].set_xlabel('Average Amount (kg)')\n",
        "axes[1].set_title('Average Feedstock Usage', fontweight='bold')\n",
        "axes[1].grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_07_feedstock_composition.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "fig.suptitle('Climate Variables vs Biogas Production', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Temperature\n",
        "axes[0, 0].scatter(df['Temperature (C)'], df['biogas_production'], alpha=0.3, s=10)\n",
        "axes[0, 0].set_xlabel('Temperature (¬∞C)')\n",
        "axes[0, 0].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 0].set_title(f\"Correlation: {df['Temperature (C)'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Humidity\n",
        "axes[0, 1].scatter(df['Humidity (%)'], df['biogas_production'], alpha=0.3, s=10, color='green')\n",
        "axes[0, 1].set_xlabel('Humidity (%)')\n",
        "axes[0, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 1].set_title(f\"Correlation: {df['Humidity (%)'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Rainfall\n",
        "axes[0, 2].scatter(df['Rainfall (mm)'], df['biogas_production'], alpha=0.3, s=10, color='blue')\n",
        "axes[0, 2].set_xlabel('Rainfall (mm)')\n",
        "axes[0, 2].set_ylabel('Biogas Production (L)')\n",
        "axes[0, 2].set_title(f\"Correlation: {df['Rainfall (mm)'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[0, 2].grid(alpha=0.3)\n",
        "\n",
        "# Digester Temperature\n",
        "axes[1, 0].scatter(df['Digester Temp (C)'], df['biogas_production'], alpha=0.3, s=10, color='red')\n",
        "axes[1, 0].set_xlabel('Digester Temp (¬∞C)')\n",
        "axes[1, 0].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 0].set_title(f\"Correlation: {df['Digester Temp (C)'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# C/N Ratio\n",
        "axes[1, 1].scatter(df['C/N Ratio'], df['biogas_production'], alpha=0.3, s=10, color='purple')\n",
        "axes[1, 1].set_xlabel('C/N Ratio')\n",
        "axes[1, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 1].set_title(f\"Correlation: {df['C/N Ratio'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "# Total Feedstock\n",
        "axes[1, 2].scatter(df['Total_Feedstock'], df['biogas_production'], alpha=0.3, s=10, color='orange')\n",
        "axes[1, 2].set_xlabel('Total Feedstock (kg)')\n",
        "axes[1, 2].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 2].set_title(f\"Correlation: {df['Total_Feedstock'].corr(df['biogas_production']):.3f}\",\n",
        "                     fontweight='bold')\n",
        "axes[1, 2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_08_climate_biogas_relationships.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Using IQR method\n",
        "fig, axes = plt.subplots(3, 4, figsize=(18, 12))\n",
        "fig.suptitle('Outlier Detection (Box Plots)', fontsize=16, fontweight='bold')\n",
        "axes = axes.ravel()\n",
        "\n",
        "selected_vars = feedstocks[:10] + operational[:2]\n",
        "\n",
        "for idx, col in enumerate(selected_vars):\n",
        "    if idx < len(axes):\n",
        "        axes[idx].boxplot(df[col], vert=True)\n",
        "        axes[idx].set_title(col, fontweight='bold', fontsize=9)\n",
        "        axes[idx].grid(alpha=0.3)\n",
        "\n",
        "        # Calculate outliers\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)][col]\n",
        "        axes[idx].set_ylabel(f'n_outliers: {len(outliers)}', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_09_outlier_detection.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Select key variables for pairplot\n",
        "key_vars = ['Pig Manure (kg)', 'Kitchen Food Waste (kg)', 'Digester Temp (C)',\n",
        "            'Temperature (C)', 'C/N Ratio', 'biogas_production']\n",
        "\n",
        "# Sample data for faster plotting (optional)\n",
        "df_sample = df[key_vars].sample(n=min(2000, len(df)), random_state=42)\n",
        "\n",
        "pairplot = sns.pairplot(df_sample, diag_kind='hist', plot_kws={'alpha': 0.4, 's': 10},\n",
        "                       diag_kws={'bins': 30, 'edgecolor': 'black'})\n",
        "pairplot.fig.suptitle('Pairwise Relationships - Key Variables',\n",
        "                      fontsize=16, fontweight='bold', y=1.01)\n",
        "plt.savefig(output_path + 'EDA_10_pairwise_relationships.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Seasonal Effects Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Temperature by season\n",
        "seasonal_temp = [df[df['Season']==s]['Temperature (C)'].values for s in ['Winter', 'Spring', 'Summer', 'Fall']]\n",
        "axes[0, 0].boxplot(seasonal_temp, labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
        "axes[0, 0].set_title('Ambient Temperature by Season', fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Temperature (¬∞C)')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Humidity by season\n",
        "seasonal_humidity = [df[df['Season']==s]['Humidity (%)'].values for s in ['Winter', 'Spring', 'Summer', 'Fall']]\n",
        "axes[0, 1].boxplot(seasonal_humidity, labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
        "axes[0, 1].set_title('Humidity by Season', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Humidity (%)')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Rainfall by season\n",
        "seasonal_rainfall = [df[df['Season']==s]['Rainfall (mm)'].values for s in ['Winter', 'Spring', 'Summer', 'Fall']]\n",
        "axes[1, 0].boxplot(seasonal_rainfall, labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
        "axes[1, 0].set_title('Rainfall by Season', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Rainfall (mm)')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Biogas by season\n",
        "seasonal_biogas = [df[df['Season']==s]['biogas_production'].values for s in ['Winter', 'Spring', 'Summer', 'Fall']]\n",
        "axes[1, 1].boxplot(seasonal_biogas, labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
        "axes[1, 1].set_title('Biogas Production by Season', fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Biogas Production (L)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'EDA_11_seasonal_effects.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "seasonal_summary = df.groupby('Season')[['biogas_production', 'Temperature (C)',\n",
        "                                         'Humidity (%)', 'Rainfall (mm)']].describe()\n",
        "print(seasonal_summary)\n",
        "\n",
        "# Save to CSV\n",
        "seasonal_summary.to_csv(output_path + 'seasonal_summary_statistics.csv')\n",
        "summary_report = {\n",
        "    'Total_Observations': len(df),\n",
        "    'Date_Range': f\"{df['Year'].min()}-{df['Year'].max()}\",\n",
        "    'Biogas_Mean': df['biogas_production'].mean(),\n",
        "    'Biogas_Std': df['biogas_production'].std(),\n",
        "    'Biogas_Min': df['biogas_production'].min(),\n",
        "    'Biogas_Max': df['biogas_production'].max(),\n",
        "    'Top_Feedstock': df[feedstocks].mean().idxmax(),\n",
        "    'Top_Feedstock_Avg': df[feedstocks].mean().max(),\n",
        "    'Strongest_Positive_Correlation': biogas_corr.drop('biogas_production').idxmax(),\n",
        "    'Strongest_Correlation_Value': biogas_corr.drop('biogas_production').max(),\n",
        "    'Average_Temperature': df['Temperature (C)'].mean(),\n",
        "    'Average_Humidity': df['Humidity (%)'].mean(),\n",
        "    'Average_CN_Ratio': df['C/N Ratio'].mean(),\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame([summary_report])\n",
        "summary_df.to_csv(output_path + 'EDA_summary_report.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ EXPLORATORY DATA ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìÅ All outputs saved to: {output_path}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - EDA_01_feedstock_distributions.png\")\n",
        "print(\"  - EDA_02_operational_climate_distributions.png\")\n",
        "print(\"  - EDA_03_biogas_production_analysis.png\")\n",
        "print(\"  - EDA_04_temporal_trends.png\")\n",
        "print(\"  - EDA_05_correlation_full.png\")\n",
        "print(\"  - EDA_06_biogas_correlations.png\")\n",
        "print(\"  - EDA_07_feedstock_composition.png\")\n",
        "print(\"  - EDA_08_climate_biogas_relationships.png\")\n",
        "print(\"  - EDA_09_outlier_detection.png\")\n",
        "print(\"  - EDA_10_pairwise_relationships.png\")\n",
        "print(\"  - EDA_11_seasonal_effects.png\")\n",
        "print(\"  - seasonal_summary_statistics.csv\")\n",
        "print(\"  - EDA_summary_report.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä KEY FINDINGS:\")\n",
        "print(\"=\"*80)\n",
        "for key, value in summary_report.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "kjHDdgdlfreh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BIOGAS ML PROOF-OF-CONCEPT TEST**"
      ],
      "metadata": {
        "id": "S0bAII9WPOaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üß™ BIOGAS ML PROOF-OF-CONCEPT TEST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Low carbon model/biogas_dataset.csv'\n",
        "output_path = '/content/drive/MyDrive/Low carbon model/'\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "print(f\"\\n‚úÖ Data loaded: {df.shape[0]} observations, {df.shape[1]} features\")\n",
        "\n",
        "# Define feature groups\n",
        "feedstocks = ['Pig Manure (kg)', 'Kitchen Food Waste (kg)', 'Chicken Litter (kg)',\n",
        "              'Cassava (kg)', 'Bagasse Feed (kg)', 'Energy Grass (kg)',\n",
        "              'Banana Shafts (kg)', 'Alcohol Waste (kg)', 'Municipal Residue (kg)',\n",
        "              'Fish Waste (kg)']\n",
        "\n",
        "operational = ['Water (L)', 'Diesel (L)', 'Electricity Use (kWh)',\n",
        "               'C/N Ratio', 'Digester Temp (C)']\n",
        "\n",
        "climate = ['Temperature (C)', 'Humidity (%)', 'Rainfall (mm)']\n",
        "\n",
        "# Combine all features\n",
        "all_features = feedstocks + operational + climate\n",
        "target = 'biogas_production'\n",
        "\n",
        "# Prepare X and y\n",
        "X = df[all_features].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Features prepared: {X.shape[1]} input features\")\n",
        "print(f\"   - {len(feedstocks)} feedstocks\")\n",
        "print(f\"   - {len(operational)} operational variables\")\n",
        "print(f\"   - {len(climate)} climate variables\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. TRAIN/TEST SPLIT (Temporal)\n",
        "# ============================================================================\n",
        "\n",
        "# Use 80% for training, 20% for testing (temporal split)\n",
        "split_idx = int(0.8 * len(df))\n",
        "\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "print(f\"\\n‚úÖ Data split:\")\n",
        "print(f\"   - Training: {len(X_train)} samples ({100*len(X_train)/len(X):.1f}%)\")\n",
        "print(f\"   - Testing: {len(X_test)} samples ({100*len(X_test)/len(X):.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ TESTING ML MODELS...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15,\n",
        "                                          random_state=42, n_jobs=-1),\n",
        "}\n",
        "\n",
        "# Try to import advanced models (skip if not installed)\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    models['XGBoost'] = XGBRegressor(n_estimators=100, max_depth=8,\n",
        "                                    learning_rate=0.1, random_state=42, n_jobs=-1)\n",
        "    print(\"‚úÖ XGBoost available\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  XGBoost not installed (will use RF only)\")\n",
        "\n",
        "try:\n",
        "    from lightgbm import LGBMRegressor\n",
        "    models['LightGBM'] = LGBMRegressor(n_estimators=100, max_depth=8,\n",
        "                                      learning_rate=0.1, random_state=42, n_jobs=-1,\n",
        "                                      verbose=-1)\n",
        "    print(\"‚úÖ LightGBM available\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  LightGBM not installed (will use RF only)\")\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'‚îÄ'*60}\")\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
        "\n",
        "    results[model_name] = {\n",
        "        'model': model,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'test_rmse': test_rmse,\n",
        "        'test_mae': test_mae,\n",
        "        'mape': mape,\n",
        "        'predictions': y_test_pred\n",
        "    }\n",
        "\n",
        "    print(f\"‚úÖ {model_name} Results:\")\n",
        "    print(f\"   Training R¬≤:  {train_r2:.4f}\")\n",
        "    print(f\"   Testing R¬≤:   {test_r2:.4f}\")\n",
        "    print(f\"   RMSE:         {test_rmse:.4f} L\")\n",
        "    print(f\"   MAE:          {test_mae:.4f} L\")\n",
        "    print(f\"   MAPE:         {mape:.2f}%\")\n",
        "\n",
        "    # Check for overfitting\n",
        "    overfit_gap = train_r2 - test_r2\n",
        "    if overfit_gap > 0.1:\n",
        "        print(f\"   ‚ö†Ô∏è  Overfitting detected (gap: {overfit_gap:.4f})\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ No significant overfitting (gap: {overfit_gap:.4f})\")\n",
        "\n",
        "best_model_name = max(results, key=lambda k: results[k]['test_r2'])\n",
        "best_model = results[best_model_name]['model']\n",
        "best_r2 = results[best_model_name]['test_r2']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"üèÜ BEST MODEL: {best_model_name} (R¬≤ = {best_r2:.4f})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä Generating prediction visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle(f'Model Performance: {best_model_name}', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Observed vs Predicted\n",
        "y_test_pred = results[best_model_name]['predictions']\n",
        "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.5, s=20)\n",
        "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "                'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[0, 0].set_xlabel('Observed Biogas Production (L)', fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Predicted Biogas Production (L)', fontweight='bold')\n",
        "axes[0, 0].set_title(f'Observed vs Predicted (R¬≤ = {best_r2:.4f})', fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Residuals\n",
        "residuals = y_test - y_test_pred\n",
        "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.5, s=20)\n",
        "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Predicted Biogas Production (L)', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Residuals (L)', fontweight='bold')\n",
        "axes[0, 1].set_title('Residual Plot', fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Plot 3: Residual distribution\n",
        "axes[1, 0].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Residuals (L)', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[1, 0].set_title(f'Residual Distribution (Mean: {residuals.mean():.2f} L)',\n",
        "                     fontweight='bold')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 4: Time series of predictions\n",
        "test_indices = np.arange(len(y_test))\n",
        "axes[1, 1].plot(test_indices, y_test.values, label='Observed', alpha=0.7, linewidth=1)\n",
        "axes[1, 1].plot(test_indices, y_test_pred, label='Predicted', alpha=0.7, linewidth=1)\n",
        "axes[1, 1].set_xlabel('Test Sample Index', fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Biogas Production (L)', fontweight='bold')\n",
        "axes[1, 1].set_title('Time Series: Observed vs Predicted', fontweight='bold')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'POC_model_performance.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Saved: POC_model_performance.png\")\n",
        "print(\"\\nüìä Analyzing feature importance...\")\n",
        "\n",
        "# Get feature importance\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': all_features,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nüîù TOP 10 MOST IMPORTANT FEATURES:\")\n",
        "    print(feature_importance_df.head(10).to_string(index=False))\n",
        "\n",
        "    # Plot feature importance\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    top_features = feature_importance_df.head(15)\n",
        "    ax.barh(range(len(top_features)), top_features['Importance'].values)\n",
        "    ax.set_yticks(range(len(top_features)))\n",
        "    ax.set_yticklabels(top_features['Feature'].values)\n",
        "    ax.set_xlabel('Importance', fontweight='bold')\n",
        "    ax.set_title(f'Top 15 Feature Importances ({best_model_name})',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.grid(alpha=0.3, axis='x')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path + 'POC_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"‚úÖ Saved: POC_feature_importance.png\")\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    print(\"\\nüìä Testing SHAP explainability...\")\n",
        "\n",
        "    # Use a small sample for quick test (SHAP can be slow)\n",
        "    X_sample = X_test.sample(min(500, len(X_test)), random_state=42)\n",
        "\n",
        "    # Create explainer\n",
        "    explainer = shap.TreeExplainer(best_model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "    # Summary plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False, max_display=15)\n",
        "    plt.title('SHAP Feature Importance', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path + 'POC_shap_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"‚úÖ SHAP analysis works! Saved: POC_shap_importance.png\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  SHAP not installed - install with: pip install shap\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  SHAP test failed: {e}\")\n",
        "\n",
        "print(\"\\nüìä Testing impact of different feature groups...\")\n",
        "\n",
        "feature_groups = {\n",
        "    'Feedstocks Only': feedstocks,\n",
        "    'Feedstocks + Operational': feedstocks + operational,\n",
        "    'Feedstocks + Climate': feedstocks + climate,\n",
        "    'All Features': all_features\n",
        "}\n",
        "\n",
        "group_results = {}\n",
        "\n",
        "for group_name, features in feature_groups.items():\n",
        "    X_group_train = X_train[features]\n",
        "    X_group_test = X_test[features]\n",
        "\n",
        "    # Train simple RF model\n",
        "    model_group = RandomForestRegressor(n_estimators=50, max_depth=15,\n",
        "                                       random_state=42, n_jobs=-1)\n",
        "    model_group.fit(X_group_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_group = model_group.predict(X_group_test)\n",
        "    r2_group = r2_score(y_test, y_pred_group)\n",
        "\n",
        "    group_results[group_name] = r2_group\n",
        "    print(f\"  {group_name:30s} R¬≤ = {r2_group:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã PROOF-OF-CONCEPT SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚úÖ DATA VALIDATION:\")\n",
        "print(f\"   - Dataset size: {len(df):,} observations\")\n",
        "print(f\"   - Features: {len(all_features)}\")\n",
        "print(f\"   - Target range: {y.min():.2f} - {y.max():.2f} L\")\n",
        "print(f\"   - No missing values: {X.isnull().sum().sum() == 0}\")\n",
        "\n",
        "print(f\"\\n‚úÖ MODEL PERFORMANCE:\")\n",
        "print(f\"   - Best model: {best_model_name}\")\n",
        "print(f\"   - Test R¬≤: {best_r2:.4f}\")\n",
        "print(f\"   - RMSE: {results[best_model_name]['test_rmse']:.4f} L\")\n",
        "print(f\"   - MAPE: {results[best_model_name]['mape']:.2f}%\")\n",
        "\n",
        "if 'feature_importance_df' in locals():\n",
        "    top3 = feature_importance_df.head(3)['Feature'].tolist()\n",
        "    print(f\"\\n‚úÖ TOP 3 FEATURES:\")\n",
        "    for i, feat in enumerate(top3, 1):\n",
        "        imp = feature_importance_df[feature_importance_df['Feature']==feat]['Importance'].values[0]\n",
        "        print(f\"   {i}. {feat} ({imp:.4f})\")\n",
        "\n",
        "print(f\"\\n‚úÖ FEATURE GROUP COMPARISON:\")\n",
        "for group_name, r2 in group_results.items():\n",
        "    print(f\"   {group_name:30s} R¬≤ = {r2:.4f}\")\n",
        "\n",
        "# Calculate climate contribution\n",
        "climate_contribution = group_results['All Features'] - group_results['Feedstocks + Operational']\n",
        "print(f\"\\nüìä CLIMATE CONTRIBUTION: ŒîR¬≤ = {climate_contribution:.4f}\")\n",
        "if abs(climate_contribution) < 0.02:\n",
        "    print(\"   ‚úÖ Climate has minimal impact (supports your hypothesis!)\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  Climate has noticeable impact\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ DECISION: Should you proceed with full framework?\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if best_r2 > 0.85:\n",
        "    print(\"‚úÖ YES! Strong performance (R¬≤ > 0.85)\")\n",
        "    print(\"   ‚Üí Proceed with hierarchical framework\")\n",
        "    print(\"   ‚Üí SHAP analysis will provide valuable insights\")\n",
        "    print(\"   ‚Üí Optimization will be effective\")\n",
        "elif best_r2 > 0.75:\n",
        "    print(\"‚úÖ PROBABLY YES. Good performance (R¬≤ > 0.75)\")\n",
        "    print(\"   ‚Üí Consider feature engineering to boost performance\")\n",
        "    print(\"   ‚Üí Test more advanced models (CatBoost, ensemble)\")\n",
        "elif best_r2 > 0.65:\n",
        "    print(\"‚ö†Ô∏è  MAYBE. Moderate performance (R¬≤ > 0.65)\")\n",
        "    print(\"   ‚Üí Investigate data quality issues\")\n",
        "    print(\"   ‚Üí Try non-linear feature transformations\")\n",
        "    print(\"   ‚Üí Consider domain knowledge for feature engineering\")\n",
        "else:\n",
        "    print(\"‚ùå NOT YET. Low performance (R¬≤ < 0.65)\")\n",
        "    print(\"   ‚Üí Review data quality and preprocessing\")\n",
        "    print(\"   ‚Üí Check for missing important features\")\n",
        "    print(\"   ‚Üí Consider mechanistic features\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìÅ OUTPUTS SAVED:\")\n",
        "print(\"=\"*80)\n",
        "print(\"  1. POC_model_performance.png\")\n",
        "print(\"  2. POC_feature_importance.png\")\n",
        "if 'shap' in dir():\n",
        "    print(\"  3. POC_shap_importance.png\")\n",
        "print(\"\\n‚úÖ PROOF-OF-CONCEPT COMPLETE!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "FJ9sXX_zsuvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL MODEL BIOGAS ML **"
      ],
      "metadata": {
        "id": "RHCox24hPTLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import itertools\n",
        "import networkx as nx\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Low carbon model/biogas_dataset.csv'\n",
        "output_path = '/content/drive/MyDrive/Low carbon model/'\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Define features\n",
        "feedstocks = ['Pig Manure (kg)', 'Kitchen Food Waste (kg)', 'Chicken Litter (kg)',\n",
        "              'Cassava (kg)', 'Bagasse Feed (kg)', 'Energy Grass (kg)',\n",
        "              'Banana Shafts (kg)', 'Alcohol Waste (kg)', 'Municipal Residue (kg)',\n",
        "              'Fish Waste (kg)']\n",
        "\n",
        "operational = ['Water (L)', 'Diesel (L)', 'Electricity Use (kWh)',\n",
        "               'C/N Ratio', 'Digester Temp (C)']\n",
        "\n",
        "climate = ['Temperature (C)', 'Humidity (%)', 'Rainfall (mm)']\n",
        "\n",
        "all_features = feedstocks + operational + climate\n",
        "target = 'biogas_production'\n",
        "\n",
        "X = df[all_features]\n",
        "y = df[target]\n",
        "\n",
        "# Temporal split\n",
        "split_idx = int(0.8 * len(df))\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "# Optimized hyperparameters (can tune further)\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "test_mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
        "\n",
        "print(f\"\\n‚úÖ MODEL PERFORMANCE:\")\n",
        "print(f\"   Training R¬≤:  {train_r2:.4f}\")\n",
        "print(f\"   Testing R¬≤:   {test_r2:.4f}\")\n",
        "print(f\"   RMSE:         {test_rmse:.4f} L\")\n",
        "print(f\"   MAE:          {test_mae:.4f} L\")\n",
        "print(f\"   MAPE:         {test_mape:.2f}%\")\n",
        "\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Calculate SHAP values for test set (use sample if too large)\n",
        "sample_size = min(2000, len(X_test))\n",
        "X_shap = X_test.sample(sample_size, random_state=42)\n",
        "shap_values = explainer.shap_values(X_shap)\n",
        "shap_interaction_values = explainer.shap_interaction_values(X_shap)\n",
        "\n",
        "print(f\"‚úÖ SHAP values calculated for {sample_size} samples\")\n",
        "\n",
        "# Calculate mean absolute SHAP values\n",
        "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': all_features,\n",
        "    'SHAP_Importance': mean_abs_shap\n",
        "}).sort_values('SHAP_Importance', ascending=False)\n",
        "\n",
        "print(\"\\nüîù TOP 10 FEATURES (by SHAP importance):\")\n",
        "print(feature_importance_df.head(10).to_string(index=False))\n",
        "\n",
        "# FIGURE 1: SHAP Summary Plot (Beeswarm)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "shap.summary_plot(shap_values, X_shap, plot_type=\"dot\", show=False, max_display=18)\n",
        "plt.title('SHAP Feature Importance Summary', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_01_summary_beeswarm.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_01_summary_beeswarm.png\")\n",
        "\n",
        "# FIGURE 2: SHAP Bar Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "shap.summary_plot(shap_values, X_shap, plot_type=\"bar\", show=False, max_display=18)\n",
        "plt.title('Mean Absolute SHAP Values', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_02_bar_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_02_bar_importance.png\")\n",
        "\n",
        "print(\"\\nüìä Generating partial dependence plots...\")\n",
        "\n",
        "top_6_features = feature_importance_df.head(6)['Feature'].tolist()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "fig.suptitle('SHAP Dependence Plots - Top 6 Features', fontsize=16, fontweight='bold')\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, feature in enumerate(top_6_features):\n",
        "    feature_idx = all_features.index(feature)\n",
        "    shap.dependence_plot(\n",
        "        feature_idx,\n",
        "        shap_values,\n",
        "        X_shap,\n",
        "        ax=axes[idx],\n",
        "        show=False\n",
        "    )\n",
        "    axes[idx].set_title(feature, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_03_dependence_plots.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_03_dependence_plots.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ FEEDSTOCK SYNERGY NETWORK ANALYSIS (NOVEL)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate mean absolute interaction values for all feedstock pairs\n",
        "feedstock_indices = [all_features.index(f) for f in feedstocks]\n",
        "n_feedstocks = len(feedstocks)\n",
        "\n",
        "# Initialize interaction matrix\n",
        "interaction_matrix = np.zeros((n_feedstocks, n_feedstocks))\n",
        "\n",
        "for i in range(n_feedstocks):\n",
        "    for j in range(n_feedstocks):\n",
        "        if i != j:\n",
        "            # Mean absolute interaction across all samples\n",
        "            interaction_matrix[i, j] = np.abs(\n",
        "                shap_interaction_values[:, feedstock_indices[i], feedstock_indices[j]]\n",
        "            ).mean()\n",
        "\n",
        "# Create DataFrame\n",
        "interaction_df = pd.DataFrame(\n",
        "    interaction_matrix,\n",
        "    index=feedstocks,\n",
        "    columns=feedstocks\n",
        ")\n",
        "\n",
        "print(\"\\nüìä FEEDSTOCK INTERACTION MATRIX:\")\n",
        "print(interaction_df.round(4))\n",
        "\n",
        "# Save to CSV\n",
        "interaction_df.to_csv(output_path + 'feedstock_interaction_matrix.csv')\n",
        "print(\"‚úÖ Saved: feedstock_interaction_matrix.csv\")\n",
        "\n",
        "# FIGURE 3: Interaction Heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(interaction_df, annot=True, fmt='.3f', cmap='YlOrRd',\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Feedstock Synergy Interaction Matrix (SHAP)',\n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_04_interaction_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_04_interaction_heatmap.png\")\n",
        "# Create network\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes\n",
        "for feedstock in feedstocks:\n",
        "    G.add_node(feedstock)\n",
        "\n",
        "# Calculate threshold for significant interactions (top 30%)\n",
        "all_interactions = interaction_matrix[np.triu_indices_from(interaction_matrix, k=1)]\n",
        "threshold = np.percentile(all_interactions, 70)\n",
        "\n",
        "print(f\"‚úÖ Interaction threshold: {threshold:.4f}\")\n",
        "\n",
        "# Add edges for significant interactions\n",
        "significant_pairs = []\n",
        "for i in range(n_feedstocks):\n",
        "    for j in range(i+1, n_feedstocks):\n",
        "        interaction_strength = interaction_matrix[i, j]\n",
        "        if interaction_strength > threshold:\n",
        "            G.add_edge(\n",
        "                feedstocks[i],\n",
        "                feedstocks[j],\n",
        "                weight=interaction_strength\n",
        "            )\n",
        "            significant_pairs.append((feedstocks[i], feedstocks[j], interaction_strength))\n",
        "\n",
        "print(f\"‚úÖ Identified {len(significant_pairs)} significant synergies\")\n",
        "\n",
        "# Calculate network metrics\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "\n",
        "# Identify keystone feedstocks\n",
        "keystone_feedstocks = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nüîë KEYSTONE FEEDSTOCKS (by network centrality):\")\n",
        "for i, (feedstock, centrality) in enumerate(keystone_feedstocks[:5], 1):\n",
        "    print(f\"   {i}. {feedstock}: {centrality:.3f}\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 12))\n",
        "\n",
        "# Layout\n",
        "pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
        "\n",
        "# Node sizes based on main effect (mean absolute SHAP)\n",
        "feedstock_shap_importance = {\n",
        "    f: feature_importance_df[feature_importance_df['Feature']==f]['SHAP_Importance'].values[0]\n",
        "    for f in feedstocks if f in feature_importance_df['Feature'].values\n",
        "}\n",
        "node_sizes = [feedstock_shap_importance.get(node, 0) * 100 for node in G.nodes()]\n",
        "\n",
        "# Node colors based on centrality\n",
        "node_colors = [degree_centrality[node] for node in G.nodes()]\n",
        "\n",
        "# Edge widths based on interaction strength\n",
        "edge_widths = [G[u][v]['weight'] * 20 for u, v in G.edges()]\n",
        "\n",
        "# Draw network\n",
        "nodes = nx.draw_networkx_nodes(\n",
        "    G, pos,\n",
        "    node_size=node_sizes,\n",
        "    node_color=node_colors,\n",
        "    cmap=plt.cm.viridis,\n",
        "    alpha=0.9,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "nx.draw_networkx_edges(\n",
        "    G, pos,\n",
        "    width=edge_widths,\n",
        "    alpha=0.6,\n",
        "    edge_color='gray',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "nx.draw_networkx_labels(\n",
        "    G, pos,\n",
        "    font_size=9,\n",
        "    font_weight='bold',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Add colorbar\n",
        "plt.colorbar(nodes, label='Network Centrality', ax=ax, shrink=0.8)\n",
        "\n",
        "ax.set_title(\n",
        "    'Feedstock Synergy Network\\n(Node size = main effect | Edge width = interaction strength | Color = centrality)',\n",
        "    fontsize=14, fontweight='bold', pad=20\n",
        ")\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_05_synergy_network.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_05_synergy_network.png\")\n",
        "print(\"\\nüîù TOP 10 SYNERGISTIC FEEDSTOCK PAIRS:\")\n",
        "significant_pairs_sorted = sorted(significant_pairs, key=lambda x: x[2], reverse=True)\n",
        "for i, (f1, f2, strength) in enumerate(significant_pairs_sorted[:10], 1):\n",
        "    print(f\"   {i}. {f1} √ó {f2}: {strength:.4f}\")\n",
        "\n",
        "# Save to CSV\n",
        "synergy_pairs_df = pd.DataFrame(\n",
        "    significant_pairs_sorted,\n",
        "    columns=['Feedstock_1', 'Feedstock_2', 'Interaction_Strength']\n",
        ")\n",
        "synergy_pairs_df.to_csv(output_path + 'feedstock_synergy_pairs.csv', index=False)\n",
        "print(\"‚úÖ Saved: feedstock_synergy_pairs.csv\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üå°Ô∏è CLIMATE RESILIENCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Extract SHAP values for climate variables\n",
        "climate_indices = [all_features.index(c) for c in climate]\n",
        "climate_shap = shap_values[:, climate_indices]\n",
        "\n",
        "# Calculate contribution\n",
        "climate_shap_importance = np.abs(climate_shap).mean(axis=0)\n",
        "total_shap_importance = np.abs(shap_values).mean(axis=0).sum()\n",
        "climate_contribution_pct = (climate_shap_importance.sum() / total_shap_importance) * 100\n",
        "\n",
        "print(f\"\\nüìä CLIMATE VARIABLE CONTRIBUTIONS:\")\n",
        "for i, climate_var in enumerate(climate):\n",
        "    pct = (climate_shap_importance[i] / total_shap_importance) * 100\n",
        "    print(f\"   {climate_var:20s}: {pct:.2f}%\")\n",
        "\n",
        "print(f\"\\n‚úÖ Total climate contribution: {climate_contribution_pct:.2f}%\")\n",
        "\n",
        "# FIGURE 5: Climate vs Feedstock Contributions\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "categories = ['Feedstocks', 'Operational', 'Climate']\n",
        "feedstock_shap = np.abs(shap_values[:, [all_features.index(f) for f in feedstocks]]).mean()\n",
        "operational_shap = np.abs(shap_values[:, [all_features.index(o) for o in operational]]).mean()\n",
        "climate_shap_total = np.abs(shap_values[:, climate_indices]).mean()\n",
        "\n",
        "contributions = [feedstock_shap, operational_shap, climate_shap_total]\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "bars = ax.bar(categories, contributions, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "\n",
        "ax.set_ylabel('Mean |SHAP Value|', fontweight='bold', fontsize=12)\n",
        "ax.set_title('Feature Group Contributions to Biogas Production',\n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.3f}',\n",
        "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_06_feature_group_contributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_06_feature_group_contributions.png\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç LOCAL EXPLANATION EXAMPLES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find interesting cases\n",
        "residuals = y_test.values - y_pred_test\n",
        "residuals_indexed = pd.Series(residuals, index=y_test.index)\n",
        "\n",
        "# Case 1: Best prediction\n",
        "best_idx = residuals_indexed.abs().idxmin()\n",
        "best_idx_in_shap = X_shap.index.get_loc(best_idx) if best_idx in X_shap.index else 0\n",
        "\n",
        "# Case 2: Worst prediction\n",
        "worst_idx = residuals_indexed.abs().idxmax()\n",
        "worst_idx_in_shap = X_shap.index.get_loc(worst_idx) if worst_idx in X_shap.index else 1\n",
        "\n",
        "# Case 3: High yield\n",
        "high_yield_idx = y_test.idxmax()\n",
        "high_idx_in_shap = X_shap.index.get_loc(high_yield_idx) if high_yield_idx in X_shap.index else 2\n",
        "\n",
        "cases = [\n",
        "    ('Best Prediction', best_idx_in_shap),\n",
        "    ('Worst Prediction', worst_idx_in_shap),\n",
        "    ('Highest Yield', high_idx_in_shap)\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 15))\n",
        "\n",
        "for idx, (case_name, case_idx) in enumerate(cases):\n",
        "    shap.waterfall_plot(\n",
        "        shap.Explanation(\n",
        "            values=shap_values[case_idx],\n",
        "            base_values=explainer.expected_value,\n",
        "            data=X_shap.iloc[case_idx],\n",
        "            feature_names=all_features\n",
        "        ),\n",
        "        max_display=15,\n",
        "        show=False\n",
        "    )\n",
        "    axes[idx].set_title(f'{case_name}', fontweight='bold', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path + 'SHAP_07_local_explanations.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"‚úÖ Saved: SHAP_07_local_explanations.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã COMPREHENSIVE ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary_report = {\n",
        "    'Model': 'LightGBM',\n",
        "    'Test_R2': test_r2,\n",
        "    'Test_RMSE_L': test_rmse,\n",
        "    'Test_MAE_L': test_mae,\n",
        "    'Test_MAPE_pct': test_mape,\n",
        "    'Top_Feature': feature_importance_df.iloc[0]['Feature'],\n",
        "    'Top_Feature_Importance': feature_importance_df.iloc[0]['SHAP_Importance'],\n",
        "    'Climate_Contribution_pct': climate_contribution_pct,\n",
        "    'Keystone_Feedstock': keystone_feedstocks[0][0],\n",
        "    'Keystone_Centrality': keystone_feedstocks[0][1],\n",
        "    'N_Significant_Synergies': len(significant_pairs),\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ KEY METRICS:\")\n",
        "for key, value in summary_report.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Save summary\n",
        "summary_df = pd.DataFrame([summary_report])\n",
        "summary_df.to_csv(output_path + 'comprehensive_analysis_summary.csv', index=False)\n",
        "print(\"\\n‚úÖ Saved: comprehensive_analysis_summary.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ COMPREHENSIVE ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìÅ GENERATED FILES:\")\n",
        "files = [\n",
        "    'SHAP_01_summary_beeswarm.png',\n",
        "    'SHAP_02_bar_importance.png',\n",
        "    'SHAP_03_dependence_plots.png',\n",
        "    'SHAP_04_interaction_heatmap.png',\n",
        "    'SHAP_05_synergy_network.png ‚≠ê KEY FIGURE',\n",
        "    'SHAP_06_feature_group_contributions.png',\n",
        "    'SHAP_07_local_explanations.png',\n",
        "    'feedstock_interaction_matrix.csv',\n",
        "    'feedstock_synergy_pairs.csv',\n",
        "    'comprehensive_analysis_summary.csv'\n",
        "]\n",
        "\n",
        "for i, file in enumerate(files, 1):\n",
        "    print(f\"  {i}. {file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ],
      "metadata": {
        "id": "dMVKg_wwt9Ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}